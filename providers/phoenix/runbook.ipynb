{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Migrating from Arize Phoenix to LangSmith\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Migrating Resources\n",
        "\n",
        "Contained in this repo are scripts to migrate your resources from Arize Phoenix to LangSmith.\n",
        "\n",
        "This includes:\n",
        "- Datasets\n",
        "- Prompts\n",
        "- Recent Traces\n",
        "\n",
        "To migrate your resources over, refer to ```providers/phoenix/main.py```. Specific scripts for each are provided in the ```providers/phoenix/data``` directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Updating Code\n",
        "\n",
        "In the process of migrating to LangSmith, you will also need to update your instrumentation code as well. \n",
        "\n",
        "In the following sections we break down some common patterns used in Arize Phoenix, and their equivalent implementation in LangSmith. Not all features are shared, but common constructs are available across both frameworks.\n",
        "\n",
        "**Note:** The examples below require API keys to be configured in your `.env` file:\n",
        "- `OPENAI_API_KEY` - for OpenAI examples\n",
        "- `PHOENIX_API_KEY` - for Phoenix examples  \n",
        "- `LANGSMITH_API_KEY` - for LangSmith examples\n",
        "\n",
        "First, let's load in our environment variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"../../.env\", override=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Tracing**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### OpenTelemetry Auto-Instrumentation\n",
        "\n",
        "Phoenix uses OpenTelemetry for tracing with auto-instrumentation via ```phoenix.otel.register()```. This automatically instruments OpenAI, LangChain, LlamaIndex, and other frameworks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/christineastoria/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/christineastoria/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "/Users/christineastoria/Library/Python/3.9/lib/python/site-packages/phoenix/otel/otel.py:434: UserWarning: Could not infer collector endpoint protocol, defaulting to HTTP.\n",
            "  warnings.warn(\"Could not infer collector endpoint protocol, defaulting to HTTP.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî≠ OpenTelemetry Tracing Details üî≠\n",
            "|  Phoenix Project: my-llm-project\n",
            "|  Span Processor: SimpleSpanProcessor\n",
            "|  Collector Endpoint: https://app.phoenix.arize.com/s/christine/v1/traces\n",
            "|  Transport: HTTP + protobuf\n",
            "|  Transport Headers: {'authorization': '****'}\n",
            "|  \n",
            "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
            "|  \n",
            "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
            "|  \n",
            "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
            "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from phoenix.otel import register\n",
        "from openai import OpenAI\n",
        "\n",
        "# Get your Phoenix space from env (e.g., \"christine\")\n",
        "PHOENIX_SPACE = os.getenv(\"PHOENIX_SPACE\", \"\")\n",
        "\n",
        "# Register Phoenix tracing with auto-instrumentation\n",
        "tracer_provider = register(\n",
        "    project_name=\"my-llm-project\",\n",
        "    endpoint=f\"https://app.phoenix.arize.com/s/{PHOENIX_SPACE}/v1/traces\",\n",
        "    auto_instrument=True,\n",
        ")\n",
        "\n",
        "# Your code is automatically traced\n",
        "client = OpenAI()\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LangSmith provides automatic tracing via ```wrap_openai``` or the ```@traceable``` decorator. No explicit registration needed - just set your environment variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith.wrappers import wrap_openai\n",
        "from openai import OpenAI\n",
        "\n",
        "# Wrap OpenAI client for automatic tracing\n",
        "client = wrap_openai(OpenAI())\n",
        "\n",
        "# All OpenAI calls are now traced to LangSmith\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Manual Spans with OpenInference\n",
        "\n",
        "Phoenix uses OpenTelemetry spans with OpenInference semantic conventions for manual instrumentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from opentelemetry import trace\n",
        "from openinference.semconv.trace import SpanAttributes\n",
        "\n",
        "tracer = trace.get_tracer(__name__)\n",
        "\n",
        "with tracer.start_as_current_span(\"my-custom-span\") as span:\n",
        "    span.set_attribute(SpanAttributes.INPUT_VALUE, \"user input here\")\n",
        "    # Your processing logic here\n",
        "    result = \"processed result\"\n",
        "    span.set_attribute(SpanAttributes.OUTPUT_VALUE, result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LangSmith uses the ```@traceable``` decorator or ```ls.trace()``` context manager for custom spans. Input/output is automatically captured.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith import traceable\n",
        "import langsmith as ls\n",
        "\n",
        "# Using the @traceable decorator\n",
        "@traceable\n",
        "def my_custom_function(user_input: str) -> str:\n",
        "    # Input/output automatically captured\n",
        "    return f\"processed: {user_input}\"\n",
        "\n",
        "my_custom_function(\"hello\")\n",
        "\n",
        "# Or using context manager\n",
        "with ls.trace(name=\"my-custom-span\") as run:\n",
        "    result = \"processed result\"\n",
        "    run.end(outputs={\"result\": result})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### OpenTelemetry\n",
        "\n",
        "If you prefer to keep using OpenTelemetry, LangSmith supports [OTel tracing natively](https://docs.smith.langchain.com/observability/how_to_guides/tracing/trace_with_opentelemetry).\n",
        "\n",
        "You'll switch from the Phoenix OTLP endpoint to LangSmith's OTLP endpoint.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Evaluations**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Datasets\n",
        "\n",
        "Phoenix allows you to create datasets and upload examples using the SDK.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from phoenix.client import Client\n",
        "\n",
        "# Configure client for Phoenix Cloud\n",
        "PHOENIX_API_KEY = os.getenv(\"PHOENIX_API_KEY\")\n",
        "PHOENIX_SPACE = os.getenv(\"PHOENIX_SPACE\", \"\")\n",
        "base_url = f\"https://app.phoenix.arize.com/s/{PHOENIX_SPACE}\" if PHOENIX_SPACE else \"https://app.phoenix.arize.com\"\n",
        "\n",
        "px_client = Client(base_url=base_url, api_key=PHOENIX_API_KEY)\n",
        "\n",
        "# Create dataset from DataFrame\n",
        "queries = [\n",
        "    \"What is the capital of France?\",\n",
        "    \"What is the capital of Germany?\",\n",
        "]\n",
        "responses = [\n",
        "    \"Paris\",\n",
        "    \"Berlin\",\n",
        "]\n",
        "dataset_df = pd.DataFrame(data={\"query\": queries, \"response\": responses})\n",
        "\n",
        "dataset = px_client.datasets.create_dataset(\n",
        "    dataframe=dataset_df,\n",
        "    name=\"basic\",\n",
        "    input_keys=[\"query\"],\n",
        "    output_keys=[\"response\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LangSmith allows you to create datasets using the LangSmith SDK as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "# Create a dataset\n",
        "examples = [\n",
        "    {\"input\": \"What is the capital of France?\", \"expected_output\": \"Paris\"},\n",
        "    {\"input\": \"What is the capital of Germany?\", \"expected_output\": \"Berlin\"}\n",
        "]\n",
        "\n",
        "dataset_name = \"basic\"\n",
        "\n",
        "if not client.has_dataset(dataset_name=dataset_name):\n",
        "    langsmith_dataset = client.create_dataset(dataset_name=dataset_name)\n",
        "    client.create_examples(\n",
        "        inputs=[{\"text\": ex[\"input\"]} for ex in examples],\n",
        "        outputs=[{\"text\": ex[\"expected_output\"]} for ex in examples],\n",
        "        dataset_id=langsmith_dataset.id\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Experiments\n",
        "\n",
        "Running experiments with Phoenix is done through ```run_experiment```.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Experiment started.\n",
            "üì∫ View dataset experiments: https://app.phoenix.arize.com/s/christine/datasets/RGF0YXNldDo0/experiments\n",
            "üîó View this experiment: https://app.phoenix.arize.com/s/christine/datasets/RGF0YXNldDo0/compare?experimentId=RXhwZXJpbWVudDoy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "running tasks |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 (100.0%) | ‚è≥ 00:01<00:00 |  1.51it/s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Task runs completed.\n",
            "üß† Evaluation started.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "running experiment evaluations |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 (100.0%) | ‚è≥ 00:00<00:00 |  9.11it/s"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment completed: 2 task runs, 2 evaluator runs, 4 evaluations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from phoenix.client import Client\n",
        "from openai import OpenAI\n",
        "\n",
        "# Configure client for Phoenix Cloud\n",
        "PHOENIX_API_KEY = os.getenv(\"PHOENIX_API_KEY\")\n",
        "PHOENIX_SPACE = os.getenv(\"PHOENIX_SPACE\", \"\")\n",
        "base_url = f\"https://app.phoenix.arize.com/s/{PHOENIX_SPACE}\" if PHOENIX_SPACE else \"https://app.phoenix.arize.com\"\n",
        "\n",
        "px_client = Client(base_url=base_url, api_key=PHOENIX_API_KEY)\n",
        "openai_client = OpenAI()\n",
        "\n",
        "# Load the dataset we created earlier\n",
        "dataset = px_client.datasets.get_dataset(dataset=\"basic\")\n",
        "\n",
        "# Define your task - takes input dict, returns output\n",
        "def task(x):\n",
        "    question = x[\"query\"]\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": question}]\n",
        "    )\n",
        "    return {\"answer\": response.choices[0].message.content}\n",
        "\n",
        "# Define evaluators - simple functions that take output and return bool\n",
        "def has_answer(output) -> bool:\n",
        "    return bool(output.get(\"answer\"))\n",
        "\n",
        "def answer_not_empty(output) -> bool:\n",
        "    return len(output.get(\"answer\", \"\")) > 0\n",
        "\n",
        "# Run experiment using client.experiments.run_experiment()\n",
        "experiment = px_client.experiments.run_experiment(\n",
        "    dataset=dataset,\n",
        "    task=task,\n",
        "    evaluators=[has_answer, answer_not_empty]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The equivalent in LangSmith is using ```evaluate()```.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'capital-cities-eval-c67d8c74' at:\n",
            "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/04f29335-5da4-40a2-95d5-04edef724598/compare?selectedSessions=c9d0dca7-c114-484a-9eca-2b7b5d87803d\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [00:02,  1.00s/it]\n"
          ]
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "from langsmith.wrappers import wrap_openai\n",
        "from openai import OpenAI\n",
        "\n",
        "client = Client()\n",
        "dataset = client.read_dataset(dataset_name=\"basic\")\n",
        "\n",
        "# Wrap OpenAI client for tracing\n",
        "openai_client = wrap_openai(OpenAI())\n",
        "\n",
        "# Define your task function\n",
        "def my_task(inputs: dict) -> dict:\n",
        "    question = inputs[\"text\"]\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": question}],\n",
        "    )\n",
        "    return {\"output\": response.choices[0].message.content}\n",
        "\n",
        "# Define evaluation functions\n",
        "def accuracy_evaluator(inputs: dict, outputs: dict, reference_outputs: dict) -> dict:\n",
        "    output = outputs.get(\"output\", \"\")\n",
        "    expected = reference_outputs.get(\"text\", \"\")\n",
        "    if expected and expected.lower() in output.lower():\n",
        "        return {\"key\": \"accuracy\", \"score\": 1.0, \"comment\": \"Correct answer found\"}\n",
        "    return {\"key\": \"accuracy\", \"score\": 0.0, \"comment\": \"Incorrect answer\"}\n",
        "\n",
        "def length_evaluator(inputs: dict, outputs: dict) -> dict:\n",
        "    output = outputs.get(\"output\", \"\")\n",
        "    return {\"key\": \"response_length\", \"score\": len(output), \"comment\": f\"Response has {len(output)} characters\"}\n",
        "\n",
        "# Run experiment\n",
        "result = client.evaluate(\n",
        "    my_task,\n",
        "    data=dataset.id,\n",
        "    evaluators=[accuracy_evaluator, length_evaluator],\n",
        "    experiment_prefix=\"capital-cities-eval\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Prompts**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Phoenix and LangSmith both have prompting interfaces in the UI and the SDK.\n",
        "\n",
        "In Phoenix, prompts are typically created in the **Phoenix UI** (Prompt Playground), then retrieved via SDK using ```client.prompts.get()```. You can also create prompts programmatically using ```client.prompts.create()```.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAIPrompt(messages=[{'role': 'system', 'content': 'You are a harsh movie critic'}, {'role': 'user', 'content': 'Do you like Inception?'}], kwargs={'model': 'gpt-4o-mini'})\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import phoenix as px\n",
        "from phoenix.client.types import PromptVersion\n",
        "\n",
        "# Configure client for Phoenix Cloud\n",
        "PHOENIX_API_KEY = os.getenv(\"PHOENIX_API_KEY\")\n",
        "PHOENIX_SPACE = os.getenv(\"PHOENIX_SPACE\", \"\")\n",
        "base_url = f\"https://app.phoenix.arize.com/s/{PHOENIX_SPACE}\" if PHOENIX_SPACE else \"https://app.phoenix.arize.com\"\n",
        "\n",
        "\n",
        "# Create a prompt programmatically with PromptVersion\n",
        "prompt_name = \"movie-critic\"\n",
        "prompt = client.prompts.create(\n",
        "    name=prompt_name,\n",
        "    version=PromptVersion(\n",
        "        [\n",
        "            {\"role\": \"system\", \"content\": \"You are a {{ criticlevel }} movie critic\"},\n",
        "            {\"role\": \"user\", \"content\": \"Do you like {{ movie }}?\"}\n",
        "        ],\n",
        "        model_name=\"gpt-4o-mini\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Get an existing prompt by name (fetches latest version by default)\n",
        "prompt = client.prompts.get(prompt_identifier=prompt_name)\n",
        "\n",
        "# Or get a specific tagged version (e.g., \"production\")\n",
        "# prompt = client.prompts.get(prompt_identifier=prompt_name, tag=\"production\")\n",
        "\n",
        "# Format the prompt with variables and use with OpenAI\n",
        "from openai import OpenAI\n",
        "\n",
        "prompt_vars = {\"criticlevel\": \"harsh\", \"movie\": \"Inception\"}\n",
        "formatted_prompt = prompt.format(variables=prompt_vars)\n",
        "\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LangSmith has ```push_prompt``` and ```pull_prompt``` functions in the SDK for managing prompts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'https://smith.langchain.com/prompts/movie-critic/bc956426?organizationId=ebbaf2eb-769b-4505-aca2-d11de10372a4'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "client = Client()\n",
        "\n",
        "# Create a prompt with model binding\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "prompt = ChatPromptTemplate([\n",
        "    (\"system\", \"You are a {criticlevel} movie critic\"),\n",
        "    (\"human\", \"Do you like {movie}?\")\n",
        "])\n",
        "chain = prompt | model\n",
        "\n",
        "# Push to LangSmith\n",
        "client.push_prompt(\"movie-critic\", object=chain)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "messages=[SystemMessage(content='You are a harsh movie critic', additional_kwargs={}, response_metadata={}), HumanMessage(content='Do you like Inception?', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ],
      "source": [
        "# Pull and use a prompt\n",
        "prompt = client.pull_prompt(\"movie-critic\")\n",
        "\n",
        "# Invoke with variables\n",
        "response = prompt.invoke({\"criticlevel\": \"harsh\", \"movie\": \"Inception\"})\n",
        "print(response)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
